--- 
title: "Synthetic population generation for ACRES project"
author: "Flannery Black-Ingersoll and Chad Milando"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [articles.bib, packages.bib, zotero.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This book describes the process and applications of using the CO model to create a synthetic population for MyWRA, and estimate the impact of climate-change adaptation efforts."
---

# Prerequisites

Here we will describe the overall purpose of the project, with some links.
and probably embed and image or two.
```{r include=FALSE}
library(tigris)
library(leaflet) #https://rstudio.github.io/leaflet/basemaps.html
library(sf)
library(dplyr)
library(utils)
library(readr)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# Plot tract polygons and puma polygons together
MA_pumas <- pumas(state = "MA", year = 2021)
pumas <- c("00503",
           "00505",
           "02800",
           "01000",
           "00508",
           "00507",
           "00506",
           "03302",
           "00505",
           "03306",
           "01300")
MA_pumas_mywra <- subset(MA_pumas, MA_pumas$PUMACE10 %in% pumas)
MA_tracts <- tracts(state = "MA", year = 2021)

my_dir <- "~/Desktop/SUMMER2023/ResearchRotation/synthetic_population_code/ACRESr/mywra_tractsbypuma/"
PUMA00503 <- read.table(paste0(my_dir,"PUMA00503.txt"))
PUMA00503 <- unique(substr(PUMA00503$V1, 6,11))
PUMA00503_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA00503)
  
PUMA00505 <- read.table(paste0(my_dir,"PUMA00505.txt"))
PUMA00505 <- unique(substr(PUMA00505$V1, 6,11))
PUMA00505_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA00505)

PUMA00506 <- read.table(paste0(my_dir,"PUMA00506.txt"))
PUMA00506 <- unique(substr(PUMA00506$V1, 6,11))
PUMA00506_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA00506)

PUMA00507 <- read.table(paste0(my_dir,"PUMA00507.txt"))
PUMA00507 <- unique(substr(PUMA00507$V1, 6,11))
PUMA00507_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA00507)

PUMA00508 <- read.table(paste0(my_dir,"PUMA00508.txt"))
PUMA00508 <- unique(substr(PUMA00508$V1, 6,11))
PUMA00508_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA00508)

PUMA01000 <- read.table(paste0(my_dir,"PUMA01000.txt"))
PUMA01000 <- unique(substr(PUMA01000$V1, 6,11))
PUMA01000_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA01000)

PUMA01300 <- read.table(paste0(my_dir,"PUMA01300.txt"))
PUMA01300 <- unique(substr(PUMA01300$V1, 6,11))
PUMA01300_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA01300)

PUMA02800 <- read.table(paste0(my_dir,"PUMA02800.txt"))
PUMA02800 <- unique(substr(PUMA02800$V1, 6,11))
PUMA02800_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA02800)

PUMA03302 <- read.table(paste0(my_dir,"PUMA03302.txt"))
PUMA03302 <- unique(substr(PUMA03302$V1, 6,11))
PUMA03302_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA03302)

PUMA03306 <- read.table(paste0(my_dir,"PUMA03306.txt"))
PUMA03306 <- unique(substr(PUMA03306$V1, 6,11))
PUMA03306_tracts <- subset(MA_tracts,MA_tracts$TRACTCE %in% PUMA03306)


map_2 <- leaflet() %>%
  setView(lat = 42.48, lng = -71.09, zoom = 10) %>%
  addProviderTiles(
    providers$Esri.WorldTopoMap,
    options = providerTileOptions(opacity = 0.75),
    group = "ESRI World Topographic") %>%
   addProviderTiles(
    providers$Esri.WorldGrayCanvas,
    options = providerTileOptions(opacity = 0.75),
    group = "ESRI World Gray Canvas") %>%
  addProviderTiles(
    providers$Esri.WorldImagery,
    options = providerTileOptions(opacity = 0.75),
    group = "ESRI World Imagery") %>%
    addPolygons(
    data = PUMA00503_tracts,
    # set the color of outlines
    stroke = T,
    color = "red",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 00503 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA00505_tracts,
    # set the color of outlines
    stroke = T,
    color = "blue",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 00505 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA00506_tracts,
    # set the color of outlines
    stroke = T,
    color = "orange",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 00506 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA00507_tracts,
    # set the color of outlines
    stroke = T,
    color = "darkgreen",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 00507 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA00508_tracts,
    # set the color of outlines
    stroke = T,
    color = "magenta",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 00508 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA01000_tracts,
    # set the color of outlines
    stroke = T,
    color = "purple",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 01000 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA01300_tracts,
    # set the color of outlines
    stroke = T,
    color = "goldenrod",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 01300 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA02800_tracts,
    # set the color of outlines
    stroke = T,
    color = "tan",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 02800 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA03302_tracts,
    # set the color of outlines
    stroke = T,
    color = "pink",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 03302 Census Tracts",
    popup = ~TRACTCE
   ) %>%
  addPolygons(
    data = PUMA03306_tracts,
    # set the color of outlines
    stroke = T,
    color = "maroon",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "PUMA 03306 Census Tracts",
    popup = ~TRACTCE
   ) %>%
   addPolygons(
    data = MA_pumas_mywra,
    # set the color of outlines
    stroke = T,
    color = "black",
    fill = F,
    # set the opacity of the outline
    # set the stroke width in pixels
    weight = 1.4,
    group = "All Public Use Microdata Areas",
    popup = ~NAMELSAD10
   )%>%
  # Layers control
  addLayersControl(
    baseGroups = c("ESRI World Topographic",
                   "ESRI World Gray Canvas",
                   "ESRI World Imagery"),
    overlayGroups = c("All Public Use Microdata Areas",
      "PUMA 00503 Census Tracts",
           "PUMA 00505 Census Tracts",
           "PUMA 02800 Census Tracts",
           "PUMA 01000 Census Tracts",
           "PUMA 00508 Census Tracts",
           "PUMA 00507 Census Tracts",
           "PUMA 00506 Census Tracts",
           "PUMA 03302 Census Tracts",
           "PUMA 00505 Census Tracts",
           "PUMA 03306 Census Tracts",
           "PUMA 01300 Census Tracts"),
    options = layersControlOptions(collapsed = FALSE)
  )

# side note... look how beautiful this is: -->
# leaflet() %>%
# setView(lat = 42.40, lng = -71.09713377834885, zoom = 10) %>%
# addProviderTiles(providers$Stamen.Watercolor)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
map_2
```



<!--chapter:end:index.Rmd-->

# Introduction {#intro}

## Project Objectives 

**Overall: to develop a highly spatially-resolved synthetic population for application in epidemiological research in 10 Public Use Microdata Areas (first by census tract, then, by parcel).** 

> **1. Use and expand R code from [@milando_2021] to pull and prepare datasets from the American Community Survey (5-year detailed estimates tables) and Public Use Microdata Samples (both from the [United States Census Bureau](https://data.census.gov/)).**

> **2. Adapt Fortran code from [@milando_2021] to run on the Mac M1 chip. Use code to build the combinatorial optimization executable (hereafter referred to as *CO_BU*).**

> **3. Run CO_BU with the inputs from R code constraint tables, and read the resulting estimates, weight, and estimate_fit data from the CO_BU outputs in R.**

>**4. Develop comprehensive documentation of efforts using rBookdown (see document you are currently viewing!).**

>**5. Build an R package that interacts with Fortran and allows others to repeat this process with PUMAs across the United States (this is a bit ambitious).**

>**6. Produce a paper on the methods and provide a case study as an example of the application of this work.**



## Previous work from BUSPH
```{r, echo=FALSE}
# talk about the other papers we've done with synthetic population. 
# mirror the manuscript that is eventually created,
# more general audience
# place for all methods
```

> **Community-Wide Health Risk Assessment Using Geographically Resolved Demographic Data: A Synthetic Population Approach (Levy, Fabian, & Peters, 2014)** 

Given insufficient geographic resolution in existing datasets on population demographics, this paper models a synthetic population approach using a cumulative risk assessment (which documents risks from multiple agents)[@levy_2014]. 

Three major data inputs are used: 

  - ACS (American Community Survey) 5-year [PUMA (Public Use Microdata Area)](https://www.census.gov/programs-surveys/geography/guidance/geo-areas/pumas.html) (Individual Data)
  - ACS 5-year [Census Tract Data](https://www.census.gov/programs-surveys/acs/data.html) (Constraints)
  - [BRFSS (Behavioral Risk Factor Surveillance System)](https://www.cdc.gov/brfss/data_documentation/index.htm) (Individual Data) 
  
The ACS data inputs are used in the development of the synthetic population, while the BRFSS data input is used for the application of the synthetic population to an epidemiological analysis of predictors of the outcome (in this paper, smoking behavior). 

- The method of forming the synthetic population is *simulated annealing with probabilistic reweighting*:
  - Select a random subset of households
  - Compare the demographics of the random sample to the aggregate-level demographics distribution
  - Replace individual households to see if the fit improves
  - *Application: CO software package* [@williamson_co_2007] 
  
Key limitations: 

  - Underrepresentation of undocumented populations
  - ACS microdata uses a very small subsample to represent the population of interest
  
> **Community-Engaged Modeling of Geographic and Demographic Patterns of Multiple Public Health Risk Factors (Basra, Fabian, Holberger, French, and Levy, 2017)** 

This second publication [@basra_2017] uses the synthetic population created in the article published in 2014. 

  - [BRFSS (Behavioral Risk Factor Surveillance System)](https://www.cdc.gov/brfss/data_documentation/index.htm) data was used to assess several outcomes: BMI, exercise, fruit and vegetable consumption, and diabetes prevalence.
  - Regression models included: multivariable logistic regression for exercise, fruit and vegetable consumption, and diabetes prevalence; multivariable linear regression for BMI. 
  
Key limitations: 

  - ACS variables do not capture the full breadth of exposures predicting these outcomes
  - Undocumented populations are excluded from census datasets
  - Limitations of the BRFSS methodology 


> **Modeling the impact of exposure reductions using multi-stressor
epidemiology, exposure models, and synthetic microdata:
an application to birthweight in two environmental
justice communities (Milando, Yitshak-Sade, Zanobetti, Levy, Laden, and Fabian, 2020)**

This third publication expands on the synthetic population methods and looks at changes in birthweight distribution as a result of simulated environmental changes [@milando_2021].

Key data inputs:

  - ACS (American Community Survey) 5-year [PUMA (Public Use Microdata Area)](https://www.census.gov/programs-surveys/geography/guidance/geo-areas/pumas.html) (Individual Data)
  - ACS 5-year [Census Tract Data](https://www.census.gov/programs-surveys/acs/data.html) (Constraints)
  - MA Births [State Data](https://www.mass.gov/doc/2010-report-2/download) (Age, race-adjusted birth rates; probability distributions for gestational age, parity, smoking during pregnancy and goverment support)

- The method of forming the synthetic population is an expansion of the methods applied for the prior two papers, with two rounds of *simulated annealing*:
  - Simulated annealing with replacement to create a synthetic population for Chelsea and Dorchester
  - Simulated annealing without replacement, with probability sampling and logistic regression to create synthetic population of women giving birth
  - In application of the generated synthetic population, this study applies probabilistic and regression modeling to predictions of newborn birthweight outcomes
  - Used Monte Carlo to introduce uncertainty to predictions of sociobehavioral and clinical risk factors
  - *Application: CO software package* [@williamson_co_2007] 
  
Key limitations: 

  - Same probability given to all possible birthdays
  - Monte Carlo methods likely don't fully account for uncertainty
  - Only looked at the census tract level, higher spatial resolution would improve simulation
  - Challenge of assigning exposure directly rather than estimating via proxy variables




<!--chapter:end:01-intro.Rmd-->

# Literature

*Some literature on approaches to synthetic population generation:*

## PopGen

> **Synthetic population generator: PopGen (Mobility Analytics Research Group, 2016)** 

> **Enhanced synthetic population generator that accomodates control variables at multiple geographic resolutions (Konduri, You, Garikapati, and Pendyala, 2016)** 

> **A methodology to match distributions of both household and person attributes in the generation of synthetic populations (Ye, Konduri, Pendyala, Sana, and Waddell, 2009)** 




The PopGen software [@marg2016] was designed by the Mobility Analytics Research Group, with the main team of scientists cited in the second source above [@konduri2016], and was last updated in 2016. 

The methodology was presented at the 8th Annual Meeting of the Transportation Research Board in Washington, D.C., USA and is described in [@ye2009]. 

*N.B. Might want more here but methods are mathematically complex; requires further reading.* 

## PopSynWin

> **Creating a synthetic population: A comparison of tools (Jain, Ronald, and Winter, 2015)** 

This article was produced for the 3rd Conference of the Transportation Research Group of India by a group of infrastructure engineers at The University of Melbourne, Australia [@jain_2015]. The work generates and compares synthetic populations using two software programs: PopSynWin (iterative proportional fitting algorithm) and PopGen (see above, iterative proportional update algorithm). Differences between actual and synthesized population characteristics are presented. Authors concluded that the PopGen software yielded better results, with closer matches of person level characteristic distributions to that of the actual population. 


## synthpop R

> **synthpop: Bespoke Creation of Synthetic Data in R (Nowok, Raab, & Dibben, 2016)** 

The [synthpop](https://www.jstatsoft.org/article/view/v074i11) R package was published in 2016 and is described in [@nowok2016] with a step-by-step example. 

  - Can choose between several sampling method options to develop synthetic data: 
  
    - random sample from observed data (default)
    - function of other synthesized data
    - non-parametric methods: [classification and regression trees](https://cran.r-project.org/web/packages/rpart/index.html)
    - parametric methods: synthesis based on variable type (numeric, binary, unordered and order factors)
      - normal linear regression (preserving marginal distribution/not)
      - logistic regression
      - (ordered/not) polytomous logistic regression
      - predictive mean matching)
      
## simPop R

> **Simulation of Synthetic Complex Data: The R Package simPop (Templ, Meindl, Kowarik & Dupriez, 2017)** 

The [simPop](https://cran.r-project.org/web/packages/simPop/index.html) R package was published in 2022 and is described in [@Templ2017]. 



<!--chapter:end:02-literature.Rmd-->

# Methods

To generate synthetic populations for each Public Use Microdata Area (PUMA) 
contained within the Mystic River Watershed area, we used a combination of 
coding languages (R version 4.2.2 (2022-10-31) and Fortran) and a combination of datasets to generate 
PUMA-specific constraint tables. Note that the geographic resolution used for these
methods is the census tract level. 

```{r methods-image,echo=FALSE,out.width=700,fig.cap="Using PUMA and ACS to Generate a Synthetic Population"}
setwd("~/Desktop/SUMMER2023/ResearchRotation/github_acres/synthpop-bookdown/")
 knitr::include_graphics("images/methods-image.png")
```

**OVERVIEW:** 


Obtaining the datasets required: 

1. Creating lists of census tracts located in each of the 10 PUMAs using R
2. Pulling ACS census tract data for each of the 10 PUMA sets of census tracts using R
3. Pulling the Public Use Microdata Samples for each PUMA, including person and household variables

The datasets are then cleaned: 

1. ACS dataset are cleaned and combined in R (with separate runs for each PUMA)
2. PUMS data is cleaned and combined in R (with separate runs for each PUMA) 

N.B. (1) and (2) above generate output textfiles which can then be read into and implemented in the CO model, which is written in Fortran.

Update a few additional tables: 

1. Constraining tables information textfile. This file is also an output file with parameters used to reflect different ancestry bins by PUMA.
2. Control parameters file with PUMA name, number of constraint cells for that PUMA, and row below (number of constraint cells x 10).

Run with CO_BU.exe, the executable created by compiling Fortran code.  

Read the resulting output from the CO work using R. 


## Geographic area 

There are 21 cities and towns included in the Mystic River Watershed area: 

1. Burlington 
2. Lexington 
3. Belmont 
4. Watertown 
5. Arlington 
6. Winchester 
7. Woburn 
8. Reading 
9. Stoneham 
10. Medford 
11. Somerville 
12. Cambridge 
13. Boston (East Boston, Charlestown) 
14. Everett 
15. Malden 
16. Melrose 
17. Wakefield 
18. Chelsea 
19. Revere 
20. Winthrop 
21. Wilmington 


## ACS constraint tables 

ACS 5-year (2021) detailed estimates tables for Massachusetts census tracts were obtained. 

### Race/Ethnicity 

  - B04006 [People Reporting Ancestry](https://data.census.gov/table?q=B0400&g=040XX00US25&tid=ACSDT1Y2021.B04006) 
    - Collapsed by town/city: all ancestry groups with more than 1% of the population represented are retained, those with less than 1% are collapsed to 'other'
  - B03001 [Hispanic or Latino by Specific Origin](https://data.census.gov/table?q=B03001&g=040XX00US25,25$1400000) 
  
  Note that ACS 5-year (2021) detailed estimates tables include People Reporting Single Ancestry, People Reporting Multiple Ancestry, and a combined table of both - People Reporting Ancestry (B04006, used here). In order to approximate the first-ancestry reported, as this is the ancestry included in the PUMS (see section below), we did some re-weighting of the B04006 table variables. In brief, this method was as follows:   
  
  For a given PUMA (Public Use Microdata Area) in the set of 10 included PUMAs, and for each census tract within that PUMA, we re-weight all ancestry variables by proceeding across columns.   
  
  If true total $= total_{true}$ and total with multiple ancestries $= total_{obs}$, and observed population in a given ancestry column for that row $= Z_{obs}$, then the re-weighted $Z_{rw}$ is   
  
  $$
  Z_{rw} = k*Z_{obs} = {\frac{total_{obs}}{total_{true}}}*Z_{obs}
  $$
  To round to whole units of persons, we use a probabilistic coin-toss methodology:   
  
  Let the probability of rounding up be $mod(Z_{rw},1)$.  
  
  Using the 'set.seed()' function in R, generate a random number, $P$, between 0 and 1.   
  
  Then, the rounded number is:  
  
  $$
  Z_{rw-integer} = Z_{rw}-mod(Z_{rw},1)+P.
  $$
  This is helpful, except when the new total, $total_{new}$ no longer equals $total_{true}$.To amend this, we apply a 'fudge factor': 
  Rank all ancestry columns based on $Z_{rw_integer}$. Based on the difference between $total_{true}$ and $total_{new}$, we adjust the data as needed:   
  
  If $total_{new}-total_{true} = 0$, then do nothing.   
  
  If $total_{new}-total_{true} = total_{diff} > 0$, remove 1 from each of the top $n = total_{diff}$ ranked ancestries.   
  If $total_{new}-total_{true} = total_{diff} < 0$, add 1 to each of the top $n = total_{diff}$ ranked ancestries.  
  
  We keep ancestry variables where the proportion of the PUMA of that background equals or exceeds 1%. This means different ancestry variables were included for different PUMAs. The following table provides the list of included ancestries by PUMA. 
  
```{r nice-tab0, echo=FALSE, tidy=FALSE, message = FALSE, warning = FALSE}
library(readr)
PUMAS <- list("01300", "03306", "00505", "03302", "00506", "00507", "00508",
              "01000", "02800","00503")
table_list <- vector(mode = "list")
for (puma in PUMAS){
  table <- read_csv(paste0("/docs/ACS_ancestry_PUMA", puma, ".csv"))
  table_list[[puma]] <- table
}
knitr::kable(table_list[["01300"]], caption = '**PUMA01300 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["03306"]], caption = '**PUMA03306 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["00505"]], caption = '**PUMA00505 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["03302"]], caption = '**PUMA03302 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["00506"]], caption = '**PUMA00506 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["00507"]], caption = '**PUMA00507 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["00508"]], caption = '**PUMA00508 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["01000"]], caption = '**PUMA01000 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["02800"]], caption = '**PUMA02800 Ancestry Mappings**', booktabs = TRUE)
knitr::kable(table_list[["00503"]], caption = '**PUMA00503 Ancestry Mappings**', booktabs = TRUE)

```   

### Sex and Age 

  - B01001 [Sex by Age](https://data.census.gov/table?q=B01001&g=040XX00US25,25$1400000) 
  
### Education 

  - B15001 [Sex by educational attainment for the population 18 years and over](https://data.census.gov/table?q=B15001&g=040XX00US25,25$1400000) 
  

### Householder Age and Household Income 

  - B19307 [Age of householder by household income in the past 12 months (2021 inflation-adjusted dollars)](https://data.census.gov/table?q=B19037&g=040XX00US25,25$1400000) 
  
### Householder Age and Tenure 

  - B25007 [Tenure by Age of Householder](https://data.census.gov/table?q=B25007&g=040XX00US25,25$1400000) 
  



## PUMS data 

ACS 5-year (2017-2021) Public Use Microdata Sample (PUMS) files for *person* data and for *household* data. These data sample approximately 5% of individual responses to the ACS. Full documentation on this data is provided in the [PUMS User Guide](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/2017_2021ACS_PUMS_User_Guide.pdf).

We have downloaded the PUMS data at the highest spatial resolution available: PUMA (Public Use Microdata Area), geographic units developed in the Decennial Census (here, 2010) of approximately 100,000 people per PUMA. 

```{r nice-tab2, echo=FALSE, tidy=FALSE}
library(readr)
person <- read_csv("PUMA_p_variables.csv")
hhold <- read_csv("PUMA_h_variables.csv")
knitr::kable(person, caption = '**Relevant PUMS Person Variables**', booktabs = TRUE)
knitr::kable(hhold, caption = '**Relevant PUMS Household Variables**', booktabs = TRUE)
```

## ACS and PUMS Mapping 

Because ACS and PUMS variables within tables differ, we create variable mappings between the two datasets for each table. Some mappings are more complex than others (like Ancestry and Hispanic/Latino(a) tables). All are made into factor variables with integers used to indicate categories. The following sections outline the mappings and factors created by constraint variable:

**Age (B01001)**

Age is a continuous variable in the PUMS dataset. We create age breaks at {0, 17, 24, 34, 44, 64, 200} and make a factor variable (1:6). 

Age is a categorical variable in the ACS dataset (as shown above). We use the following mapping to coerce the ACS data into 6 categories that will correspond to the PUMS breaks. 

```{r nice-tab3, echo=FALSE, tidy=FALSE}
library(readxl)

B01001 <- read_excel("acs_pums_mappings.xlsx", sheet = "B01001")
knitr::kable(B01001, caption = '**B01001 Mapping**',booktabs = TRUE)
```

**Sex (B01001)** 

The sex variable mappings do not require complex mappings (Male (1) and Female(2)). 

**Education (B15001)** 

The education ACS tables do not include the population under 18 years of age. In order for CO_BU.exe to function properly, the person-variables in the estimates_constraints.txt input need to sum to the respective total populations in the census tract. We complete the population for the education section of variables by calculating the remaining under 18 population (using B01001) and include this as a column in the education categories.

```{r nice-tab4, echo=FALSE, tidy=FALSE}
library(readxl)

B15001 <- read_excel("acs_pums_mappings.xlsx", sheet = "B15001")
knitr::kable(B15001, caption = '**B15001 Mapping**',booktabs = TRUE)
```

**Householder Age and Household Income (B19037)**

Mapping of householder age and household income variables requires setting breaks in PUMS variables (which are continuous integers) that correspond to the ACS categorical values for these variables.Note that householder age from B19037 contains fewer categories than householder age in B25007 (see next subsection). 

Additionally, note the added category in the ACS column for B19037 Household Income Mapping. A column of all 0 values is included in the ACS inputs to the estimation_constraints.txt data file in order to provide mapping to the NAs included in the PUMS data.

```{r nice-tab5, echo=FALSE, tidy=FALSE}
library(readxl)

B19037_age <- read_excel("acs_pums_mappings.xlsx", sheet = "B19037_age")
knitr::kable(B19037_age, caption = '**B19037 Householder Age Mapping**',booktabs = TRUE)
B19037_income <- read_excel("acs_pums_mappings.xlsx", sheet = "B19037_income")
knitr::kable(B19037_income, caption = '**B19037 Household Income Mapping**',booktabs = TRUE)
```

**Householder Age and Tenure (B25007)** 

Mapping of householder tenure requires mapping multiple PUMS tenure categories to individual ACS categories. An additional category is also created for PUMS NA values, and a column of all 0 values is included in the ACS inputs to the estimation_constraints.txt data file in order to provide mapping to the NAs included in the PUMS data.

Additionally, note the added category in the ACS column for B25007 Household Tenure Mapping. A column of all 0 values is included in the ACS inputs to the estimation_constraints.txt data file in order to provide mapping to the NAs included in the PUMS data.

```{r nice-tab6, echo=FALSE, tidy=FALSE}
library(readxl)

B25007_age <- read_excel("acs_pums_mappings.xlsx", sheet = "B25007_age")
knitr::kable(B25007_age, caption = '**B25007 Householder Age Mapping**',booktabs = TRUE)
B25007_tenure <- read_excel("acs_pums_mappings.xlsx", sheet = "B25007_tenure")
knitr::kable(B25007_tenure, caption = '**B25007 Household Tenure Mapping**',booktabs = TRUE)
```


## R Code Guide

This section details the R project structure (hereafter referred to as ACRESr.proj) implemented prior to running CO_BU.exe. 

**Step 1. Pulling ACS Data.** 
Run the following code (only need to run 1x):
[ACS] - 0 - Grab ACS Data.R  

Objectives: 

* Pull all raw census data using census API calls  

* Provide census API key. 

* Pull all custom functions (custom-functions.R). 

* Define the PUMAs with census tracts to be included in each. 
* Run through each individual file that pulls data:  
    * [ACS] - 0 - i - Ancestry.R. 
      * This script uses a reweight function (process_puma) to get the totals to
      align with the totals for other categories. 
      * This script also uses a grab_top_i_percent function to collapse the number
      of categories to those contributing at least i% of the total population.  
    * [ACS] - 0 - i - Hispanic and Latino.R   
      * This script also uses a grab_top_i_percent function to collapse the number
      of categories to those contributing at least i% of the total population.  
    * [ACS] - 0 - ii - Sex and Age.R. 
    * [ACS] - 0 - iii - Education.R. 
    * [ACS] - 0 - iv - HHage and HHincome.R. 
    * [ACS] - 0 - v - HHage and Tenure.R. 
    
**Step 2. Output Estimation Constraints and Area List.**
Run the following code (run 1x per PUMA, adjusting inputs for lines 16-18):  
[ACS] - 1 - combine all.R. 

Objectives: 

* For a given PUMA and its corresponding tracts, pull ACS columns into a table (estimation_constraints) and list all tracts (Area_list). 

To do after running: 
  
  * Copy output from this script into CO_BU_MAC/Data. 
  
  * Copy printed output for calc_pearson.xlsx, and then take the resulting excel column and paste into the constraining_tables_info.txt file in CO_BU_MAC/Data. 
  
  * Go to MA census tract data/ancestry - hispanic B03001/ and copy the resulting hispanic mapping files into the script [PUMS] - 1 - i - Create Ancestry and Hispanic and Latino Mappings.R 
  
  * Go to MA census tract data/ancestry B04006/ and copy the resulting ancestry mapping files into the script [PUMS] - 1 - i - Create Ancestry and Hispanic and Latino Mappings.R 
  
**Step 3. Create Mapped Person and Mapped House files using PUMS data.** 
Run the following code: [PUMS] - 1 - Read in PUMS data.R (run 1x per PUMA, adjusting lines 39 and 40). 

Objectives: 

* For a given PUMA, produce person and household inputs using the PUMA, subset to the variables corresponding to those provided in the ACS table constraints used.  

  * This code runs all four [PUMS] scripts, creating mappings with [PUMS] - 1 - i - Create Ancestry and Hispanic and Latino Mappings.R, grabbing person data in [PUMS] - 1 - ii - person data.R, household data in [PUMS] - 1 - iii - house data.R, and finally creating the output files in [PUMS] - 1 - iv - convert PUMS to CO.R  
  
To do after running: 

  * Copy the mapped_person, mapped_house, and house_serials text files from the ACRESr output folder into CO_BU_MAC/Data. 


## Bring into the CO model

### Prepare Data: 

As described in the R Code, you should have the following files in CO_BU_MAC/Data, as listed in CO_filelist.txt (each with the PUMA indicated at the end of the file name, except for CO_random_seednumbers.txt as this does not need to change). 

1. 'Data/mapped_house_PUMA.txt' 

2. 'Data/mapped_person_PUMA.txt' 

3. 'Data/estimation_constraints_PUMA.txt' 

4. 'Data/Area_list_PUMA.txt' 

5. 'Data/constraining_tables_info_PUMA.txt' 

6. 'Data/control_parameters_PUMA.txt' 
    * Correct line 3 to reflect the name of the folders where you would like the output from CO_BU run to go (see within Estimates and Estimate_Fit). Suggested label: PUMA#. 
    * Correct lines 7 and 8 to reflect the number of constraint cells (line 7) (see calc_pearson.xlsx for this) and the number of constraint cells scaled by 10x (line 8). 

7. 'Data/CO_random_seednumbers.txt' 

### Run CO_BU.exe 

In the terminal, with the directory set to the co-bu-mac folder, run the following: 

1. The make file, make.sh using the code: 

    cd Code

    sh make.sh 


2. Then, in order to run the executable (should see the executable has been created in the co-bu-mac folder): 

    cd .. 

    codesign -s - CO_BU     
    
    [Why codesign? See here for explanation.](https://eclecticlight.co/2020/08/22/apple-silicon-macs-will-require-signed-code/) 
    
3. Run the executable:

    co-bu-mac % ./CO_BU



### Phase 1: with replacement

This we will do for basic demographics, the 14 characteristics as before

### Phase 2: without replacement

This we will do once we have the housing data Jon shared

## Exporting from the CO model


<!--chapter:end:03-method.Rmd-->

# Applications

Some _significant_ applications are demonstrated in this chapter.

## Flooding

## Something else

<!--chapter:end:04-application.Rmd-->

# Final Words

We have finished a nice book.

<!--chapter:end:05-summary.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-}
'`

<!--chapter:end:06-references.Rmd-->

